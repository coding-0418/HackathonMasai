# -*- coding: utf-8 -*-
"""01_train_models

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11IhSrR1SjXFnM9lHsGzzOPnp_veS1Vy-
"""

import pandas as pd
import numpy as np
import os
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier

# Load dataset
df = pd.read_csv("sample_dataset_18000.csv")
X = df.drop("target", axis=1)
y = df["target"]

# Preprocessing
X = pd.get_dummies(X, drop_first=True)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)

# Models and hyperparameter grids
models = {
    "Logistic Regression": (LogisticRegression(max_iter=1000), {}),
    "Decision Tree": (DecisionTreeClassifier(), {
        "max_depth": [5, 10, None],
        "min_samples_split": [2, 5]
    }),
    "Random Forest": (RandomForestClassifier(), {
        "n_estimators": [100, 200],
        "max_depth": [10, None]
    }),
    "SVM": (SVC(probability=True), {
        "C": [0.1, 1],
        "kernel": ["linear", "rbf"]
    }),
    "XGBoost": (XGBClassifier(eval_metric='logloss'), {
        "n_estimators": [100, 200],
        "max_depth": [3, 6],
        "learning_rate": [0.1, 0.2]
    }),
    "LightGBM": (LGBMClassifier(), {
        "n_estimators": [100, 200],
        "num_leaves": [31, 50],
        "learning_rate": [0.01, 0.1]
    }),
}

results = []
best_model = None
best_auc = 0
y_true_final = None
y_proba_final = None

# Grid search for all models
for name, (model, params) in models.items():
    print(f"🔍 Tuning {name}...")
    if params:
        grid = GridSearchCV(model, params, cv=5, scoring="f1_weighted", n_jobs=-1)
        grid.fit(X_train, y_train)
        model = grid.best_estimator_
    else:
        model.fit(X_train, y_train)

    preds = model.predict(X_test)
    probas = model.predict_proba(X_test)[:, 1] if hasattr(model, "predict_proba") else None

    auc_score = roc_auc_score(y_test, probas) if probas is not None else np.nan
    f1 = f1_score(y_test, preds)

    results.append({
        "Model": name,
        "Accuracy": accuracy_score(y_test, preds),
        "Precision": precision_score(y_test, preds),
        "Recall": recall_score(y_test, preds),
        "F1-Score": f1,
        "ROC AUC": auc_score
    })

    if auc_score > best_auc and probas is not None:
        best_model = model
        best_auc = auc_score
        y_true_final = y_test
        y_proba_final = probas

# Save results
os.makedirs("results", exist_ok=True)
results_df = pd.DataFrame(results)
results_df.to_csv("results/results_df.csv", index=False)
np.save("results/y_true.npy", y_true_final)
np.save("results/y_proba.npy", y_proba_final)

print("✅ All models trained and results saved.")